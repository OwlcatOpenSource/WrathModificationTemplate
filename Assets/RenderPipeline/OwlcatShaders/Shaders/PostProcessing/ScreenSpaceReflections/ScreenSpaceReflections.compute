#pragma kernel TracingHiZ
#pragma kernel TracingScreenSpace

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/ImageBasedLighting.hlsl"
#include "../../../ShaderLibrary/Input.hlsl"
#include "../../../ShaderLibrary/Core.hlsl"
#include "../../../Lighting/DeferredData.cs.hlsl"
#include "ScreenSpaceRaytrace.hlsl"

// Tweak parameters
#define SSR_TRACE_BEHIND_OBJECTS
#define SSR_TRACE_TOWARDS_EYE
#define SSR_TRACE_EPS            0.00024414 // 2^-12, should be good up to 4K

RW_TEXTURE2D(float2, _SsrHitPointTexture);

CBUFFER_START(UnityScreenSpaceReflections)
    int   _SsrIterLimit;
    float _SsrThicknessScale;
    float _SsrThicknessBias;
    int _SsrMinDepthMipLevel;
    float _SsrRoughnessFadeEnd;
    float4 _SsrScreenSize;
    
    float4x4 _ProjectToPixelMatrix;
    float4x4 _WorldToCameraMatrix;
    float4 _ProjInfo;
    float _MaxRayTraceDistance;
    float _LayerThickness;
    float _RayStepSize;
    float3 _CameraClipInfo;
CBUFFER_END

void GetNormalAndPerceptualRoughness(uint2 positionSS, out float3 normalWS, out float perceptualRoughness)
{
    float4 normalAndSmoothness = DecodeNormalAndSmoothness(LOAD_TEXTURE2D(_CameraNormalsRT, positionSS.xy));
    normalWS = normalAndSmoothness.xyz;
    perceptualRoughness = PerceptualSmoothnessToPerceptualRoughness(normalAndSmoothness.a);
}

float3 ReconstructCSPosition(float2 S, float z)
{
    float linEyeZ = -LinearEyeDepth(z);
    return float3((((S.xy * _ScreenSize.xy)) * _ProjInfo.xy + _ProjInfo.zw) * linEyeZ, linEyeZ);
}

/** Read the camera-space position of the point at screen-space pixel ssP */
float3 GetPosition(float2 ssP)
{
    float3 P;

    P.z = SAMPLE_TEXTURE2D_LOD(_CameraDepthRT, s_point_clamp_sampler, ssP.xy, 0).x;

    // Offset to pixel center
    P = ReconstructCSPosition(float2(ssP) /*+ float2(0.5, 0.5)*/, P.z);
    return P;
}

float3 csMirrorVector(float3 csPosition, float3 csN)
{
    float3 csE = -normalize(csPosition.xyz);
    float cos_o = dot(csN, csE);
    float3 c_mi = normalize((csN * (2.0 * cos_o)) - csE);

    return c_mi;
}

[numthreads(8,8,1)]
void TracingHiZ(uint3 groupId          : SV_GroupID,
                uint3 dispatchThreadId : SV_DispatchThreadID)
{
    uint2 positionSS = dispatchThreadId.xy;
    uint2 scaledPositionSS = positionSS;
    float scale = 1;

    if (_SsrMinDepthMipLevel > 0)
    {
        scale = 1 << _SsrMinDepthMipLevel;
        scaledPositionSS *= scale;
    }

    float2 positionNDC = scaledPositionSS * _ScreenSize.zw + (0.5 * _ScreenSize.zw); // Should we precompute the half-texel bias? We seem to use it a lot

    float  deviceDepth = LOAD_TEXTURE2D(_CameraDepthRT, scaledPositionSS).r;
    float4 translucencyAndMaterialFeatures = LOAD_TEXTURE2D(_CameraTranslucencyRT, scaledPositionSS.xy);
    uint materialFeatures = UnpackByte(translucencyAndMaterialFeatures.a);

    bool killRay = deviceDepth == UNITY_RAW_FAR_CLIP_VALUE;

    if (!HasFlag(materialFeatures, MATERIALFEATURES_REFLECTIONS))
	{
		killRay = true;
	}

    float3 positionWS = ComputeWorldSpacePosition(positionNDC, deviceDepth, UNITY_MATRIX_I_VP); // Jittered
    float3 V          = GetWorldSpaceNormalizeViewDir(positionWS);

    float3 N;
    float perceptualRoughness;
    GetNormalAndPerceptualRoughness(scaledPositionSS, N, perceptualRoughness);

    float3 camPosWS = GetCurrentViewPosition();

    // Apply normal bias with the magnitude dependent on the distance from the camera.
    // Unfortunately, we only have access to the shading normal, which is less than ideal...
    float2 texelSize = _ScreenSize.zw * scale;
    positionWS  = camPosWS + (positionWS - camPosWS) * (1 - max(texelSize.x, texelSize.y) * rcp(max(dot(N, V), FLT_EPS)));
    deviceDepth = ComputeNormalizedDeviceCoordinatesWithZ(positionWS, UNITY_MATRIX_VP).z;

    // Ref. #1: Michal Drobot - Quadtree Displacement Mapping with Height Blending.
    // Ref. #2: Yasin Uludag  - Hi-Z Screen-Space Cone-Traced Reflections.
    // Ref. #3: Jean-Philippe Grenier - Notes On Screen Space HIZ Tracing.
    // Warning: virtually all of the code below assumes reverse Z.

    // We start tracing from the center of the current pixel, and do so up to the far plane.
    float3 rayOrigin = float3(scaledPositionSS + 0.5, deviceDepth);

    // TODO: this does not match GGX.
    float3 R = reflect(-V, N);

    float3 reflPosWS  = positionWS + R;
    float3 reflPosNDC = ComputeNormalizedDeviceCoordinatesWithZ(reflPosWS, UNITY_MATRIX_VP); // Jittered
    float3 reflPosSS  = float3(reflPosNDC.xy * _ScreenSize.xy, reflPosNDC.z);
    float3 rayDir     = reflPosSS - rayOrigin;
    float3 rcpRayDir  = rcp(rayDir);
    int2   rayStep    = int2(rcpRayDir.x >= 0 ? 1 : 0,
                             rcpRayDir.y >= 0 ? 1 : 0);
    float3 raySign  = float3(rcpRayDir.x >= 0 ? 1 : -1,
                             rcpRayDir.y >= 0 ? 1 : -1,
                             rcpRayDir.z >= 0 ? 1 : -1);
    bool   rayTowardsEye  =  rcpRayDir.z >= 0;

    // Note that we don't need to store or read the perceptualRoughness value
    // if we mark stencil during the G-Buffer pass with pixels which should receive SSR,
    // and sample the color pyramid during the lighting pass.
    killRay = killRay || (reflPosSS.z <= 0);
    killRay = killRay || (dot(N, V) <= 0);
    killRay = killRay || (perceptualRoughness > _SsrRoughnessFadeEnd);
#ifndef SSR_TRACE_TOWARDS_EYE
    killRay = killRay || rayTowardsEye;
#endif

    if (killRay)
    {
        return;
    }

    #define _SsrReflectsSky 0

    // Extend and clip the end point to the frustum.
    float tMax;
    {
        // Shrink the frustum by half a texel for efficiency reasons.
        const float halfTexel = 0.5;

        float3 bounds;
        bounds.x = (rcpRayDir.x >= 0) ? _ScreenSize.x - halfTexel : halfTexel;
        bounds.y = (rcpRayDir.y >= 0) ? _ScreenSize.y - halfTexel : halfTexel;
        // If we do not want to intersect the skybox, it is more efficient to not trace too far.
        float maxDepth = (_SsrReflectsSky != 0) ? -0.00000024 : 0.00000024; // 2^-22
        bounds.z = (rcpRayDir.z >= 0) ? 1 : maxDepth;

        float3 dist = bounds * rcpRayDir - (rayOrigin * rcpRayDir);
        tMax = Min3(dist.x, dist.y, dist.z);
    }

    // Clamp the MIP level to give the compiler more information to optimize.
    const int maxMipLevel = min(_DepthPyramidLodCount, 14);

    // Start ray marching from the next texel to avoid self-intersections.
    float t;
    {
        // 'rayOrigin' is the exact texel center.
        float2 dist = abs(0.5 * rcpRayDir.xy);
        t = min(dist.x, dist.y);
    }

    float3 rayPos;

    int  mipLevel  = _SsrMinDepthMipLevel;
    int  iterCount = 0;
    bool hit       = false;
    bool miss      = false;
    bool belowMip0 = false; // This value is set prior to entering the cell

    while (!(hit || miss) && (t <= tMax) && (iterCount < _SsrIterLimit))
    {
        rayPos = rayOrigin + t * rayDir;

        // Ray position often ends up on the edge. To determine (and look up) the right cell,
        // we need to bias the position by a small epsilon in the direction of the ray.
        float2 sgnEdgeDist = round(rayPos.xy) - rayPos.xy;
        float2 satEdgeDist = clamp(raySign.xy * sgnEdgeDist + SSR_TRACE_EPS, 0, SSR_TRACE_EPS);
        rayPos.xy += raySign.xy * satEdgeDist;

        int2 mipCoord  = (int2)rayPos.xy >> mipLevel;
        int2 mipOffset = (int2)_DepthPyramidMipRects[mipLevel].xy;
        // Bounds define 4 faces of a cube:
        // 2 walls in front of the ray, and a floor and a base below it.
        float4 bounds;

        bounds.xy = (mipCoord + rayStep) << mipLevel;
        bounds.z  = LOAD_TEXTURE2D(_CameraDepthRT, mipOffset + mipCoord).r;

        // We define the depth of the base as the depth value as:
        // b = DeviceDepth((1 + thickness) * LinearDepth(d))
        // b = ((f - n) * d + n * (1 - (1 + thickness))) / ((f - n) * (1 + thickness))
        // b = ((f - n) * d - n * thickness) / ((f - n) * (1 + thickness))
        // b = d / (1 + thickness) - n / (f - n) * (thickness / (1 + thickness))
        // b = d * k_s + k_b
        bounds.w = bounds.z * _SsrThicknessScale + _SsrThicknessBias;

        float4 dist      = bounds * rcpRayDir.xyzz - (rayOrigin.xyzz * rcpRayDir.xyzz);
        float  distWall  = min(dist.x, dist.y);
        float  distFloor = dist.z;
        float  distBase  = dist.w;

        // Note: 'rayPos' given by 't' can correspond to one of several depth values:
        // - above or exactly on the floor
        // - inside the floor (between the floor and the base)
        // - below the base
    #if 0
        bool belowFloor  = (raySign.z * (t - distFloor)) <  0;
        bool aboveBase   = (raySign.z * (t - distBase )) >= 0;
    #else
        bool belowFloor  = rayPos.z  < bounds.z;
        bool aboveBase   = rayPos.z >= bounds.w;
    #endif
        bool insideFloor = belowFloor && aboveBase;
        bool hitFloor    = (t <= distFloor) && (distFloor <= distWall);

        // Game rules:
        // * if the closest intersection is with the wall of the cell, switch to the coarser MIP, and advance the ray.
        // * if the closest intersection is with the heightmap below,  switch to the finer   MIP, and advance the ray.
        // * if the closest intersection is with the heightmap above,  switch to the finer   MIP, and do NOT advance the ray.
        // Victory conditions:
        // * See below. Do NOT reorder the statements!

    #ifdef SSR_TRACE_BEHIND_OBJECTS
        miss      = belowMip0 && insideFloor;
    #else
        miss      = belowMip0;
    #endif
        hit       = (mipLevel == _SsrMinDepthMipLevel) && (hitFloor || insideFloor);
        belowMip0 = (mipLevel == _SsrMinDepthMipLevel) && belowFloor;

        // 'distFloor' can be smaller than the current distance 't'.
        // We can also safely ignore 'distBase'.
        // If we hit the floor, it's always safe to jump there.
        // If we are at (mipLevel != 0) and we are below the floor, we should not move.
        t = hitFloor ? distFloor : (((mipLevel != _SsrMinDepthMipLevel) && belowFloor) ? t : distWall);
        rayPos.z = bounds.z; // Retain the depth of the potential intersection

        // Warning: both rays towards the eye, and tracing behind objects has linear
        // rather than logarithmic complexity! This is due to the fact that we only store
        // the maximum value of depth, and not the min-max.
        mipLevel += (hitFloor || belowFloor || rayTowardsEye) ? -1 : 1;
        mipLevel  = clamp(mipLevel, _SsrMinDepthMipLevel, maxMipLevel);

        iterCount++;
    }

    // Treat intersections with the sky as misses.
    miss = miss || ((_SsrReflectsSky == 0) && (rayPos.z == 0));
    hit  = hit && !miss;

    if (hit)
    {
        // Note that we are using 'rayPos' from the penultimate iteration, rather than
        // recompute it using the last value of 't', which would result in an overshoot.
        // It also needs to be precisely at the center of the pixel to avoid artifacts.
        float2 hitPositionNDC = floor(rayPos.xy) * _ScreenSize.zw + (0.5 * _ScreenSize.zw); // Should we precompute the half-texel bias? We seem to use it a lot.
        _SsrHitPointTexture[positionSS] = hitPositionNDC;
    }
}

[numthreads(8, 8, 1)]
void TracingScreenSpace(uint3 groupId          : SV_GroupID,
                        uint3 dispatchThreadId : SV_DispatchThreadID)
{
    float2 ssP = dispatchThreadId.xy * _SsrScreenSize.zw;
    uint2 positionSS = uint2(ssP.xy * _ScreenSize.xy);

    float deviceDepth = LOAD_TEXTURE2D(_CameraDepthRT, positionSS).x;
    if (deviceDepth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        return;
    }

    float3 normalWS;
    float perceptualRoughness;
    GetNormalAndPerceptualRoughness(positionSS, normalWS, perceptualRoughness);

    if (perceptualRoughness > _SsrRoughnessFadeEnd)
    {
        return;
    }

    float4 translucencyAndMaterialFeatures = LOAD_TEXTURE2D(_CameraTranslucencyRT, positionSS.xy);
    uint materialFeatures = UnpackByte(translucencyAndMaterialFeatures.a);

    if (!HasFlag(materialFeatures, MATERIALFEATURES_REFLECTIONS))
	{
		return;
	}

    // cs is CameraSpace
    float3 csN = mul((float3x3)(_WorldToCameraMatrix), normalWS);
    float3 csPosition = ReconstructCSPosition(ssP, deviceDepth);
    float3 csRayDirection = csMirrorVector(csPosition, csN);

    if (csRayDirection.z > 0.0)
    {
        //return;
    }

    // Bump the ray more in world space as it gets farther away (and so each pixel covers more WS distance)
    float rayBump = max(-0.01*csPosition.z, 0.001);
    float2 hitPixel;
    float3 csHitPoint;
    float stepCount;

    bool wasHit = castDenseScreenSpaceRay(
        csPosition + (csN) * rayBump,
        csRayDirection,
        _ProjectToPixelMatrix,
        _ScreenSize,
        _CameraClipInfo,
        0.0, //jitterFraction,
        _SsrIterLimit, // maxSteps
        _LayerThickness,
        _MaxRayTraceDistance,
        hitPixel,
        _RayStepSize,
    #ifdef SSR_TRACE_BEHIND_OBJECTS
        true,
    #else
        false,
    #endif
        csHitPoint,
        stepCount);

    if (wasHit)
    {
        float2 tsPResult = hitPixel * _ScreenSize.zw;

        _SsrHitPointTexture[dispatchThreadId.xy] = tsPResult.xy;
    }
}